Szeretném külön-külön bemutatni az egyes komponenseket. Kiemelni a komponensek által megvalósított funkciókat, és a megvalósítás szempontjából fontos részleteket. 

\section{Mikroszerviz infrastruktúra}
\subsection{Nginx}\label{sec:nginx}
A megfelelő webszerver kiválasztása során a három legelterjedtebb\cite{W3Techs_Usage_statistics_of_webservers} webszerveret --Apache, Nginx és a Cloudflare-- vettem számításba. A főbb szempontjaim a következők voltak:
\begin{itemize}
	\item legyen open source, vagy ingyenesen használható, ezzel minimalizálva a költségeket,
	\item lehetőleg minél kevesebb erőforrást használjon fel,
	\item úgy hogy közben elegendő csak statikus tartalmat kiszolgálnia.
\end{itemize}

Az IIS\footnote{Internet Information Services} --a többi open source alternatívál ellentétben-- nem felel meg az első pontnak, mivel Windows NT licenc alá tartozik.

Az Nginx alapvetően jobb az Apache-nál a statikus oldalak, a párhuzamos lekérések kiszolgálásában~\cite{nginx_performance}, emiatt szívesen használják a két alkalmazást együtt. Ilyenkor az Nginx egy fordított proxyként kezeli az ügyfeleket és a statikus tartalmak kiszolgálását, a dinamikus tartalmakat pedig továbbítja az Apache szerver felé.

Mivel nekünk elegendő statikus tartalmat kiszolgálni --hiszen a helpdesk frontend egy egyszerű statikus HTML-oldallá fordul (lásd \ref{sec:angular}~pont)-- így adja magát, hogy webszerverként az Nginx-et használjam.

\bigskip
Az Nginx-nek tehát három különböző szerepe van:

\begin{itemize}
	\item A \foreignlanguage{british}{helpdesk frontend} alkalmazásszervereként működik (\ref{sec:angular}~pont),
	
	\item \foreignlanguage{british}{Routing}ot valósít meg, rajta kerestül érhető el a \foreignlanguage{british}{helpdesk backend} és a \foreignlanguage{british}{keycloak} szerviz,
	
	\item \foreignlanguage{british}{HTTP cache}-ként működik a frontend és a backend között.
\end{itemize}

A loadbalancer funkcionalitás --mivel a docker azt natívan támogatja, így-- a \foreignlanguage{british}{docker round-robin DNS}-én (\ref{sec:docker}) keresztül valósul meg.


\subsection{Docker konténerizáció}\label{sec:docker}
Az alakalmazás összes szervize saját docker konténerben fut. A docker konfigurációs leírása a \textit{docker-compose.yml} állományban van. A \textit{docker-compose} parancs ez alapján indítja el az alkalmazást, hozza létre a saját alhálózatát, valósítja meg a hálózaton belüli DNS-funkciót.

A konténerek skálázása  is a dockeren keresztül (\textit{docker-compose --scale}) valósul meg.



\subsection{Metrikák}\label{sec:metrikak}
Hogy megtaláljam a legmegfelelőbb monitorozó eszközt, összevetettem a három leginkább használt alternatívát, a prometheust, grafanát és a graphite-ot.

\subsubsection{Prometheus}
Prometheus egy open source monitorozó eszköz. Kifejezetten alkalmas a metrikák idősoros tárolására, gyűjtésére, és megjelenítésére.

A Prometheus által létrehozott és használt PromQL\footnote{Prometheus Query Language} lekérdező nyelv segítségével könnyen lehet az adatokból táblázatot vagy grafikont készíteni. A PromQL-ben létrehozott kifejezések alkalmasak riasztások létrehozására is, ilyenkor a hibásnak tekintett eseményről --a Prometheus \textit{Alertmanager}-én keresztül-- képes a riasztást kiváltó helyzet elhárításában érintetteket értesíteni.

A megjelenítésre használt \textit{Console template} meglehetősen sok és szerteágazó funkcióval rendelkezik. A rendelkezésre álló átfogó dokumentáció ellenére is jelentős időt vesz igénybe a legalapvetőbb grafikonok elkészítése.

A Prometheus HTTP-n keresztül tudja a megfigyelt rendszerek állapotát szabályos időintervallumokban lekérdezni. Az integrációt nagyban segíti, hogy összeköthető \textit{service discovery} szerverekkel.

\subsubsection{Grafana}
Grafana egy open source adatelemző, megjelenítő és monitorozó eszköz.

Nem tárol vagy gyűjt adatot, de támogat többféle --Graphite, Prometheus, Influx DB, ElasticSearch, MySQL, PostgreSQL-- adatforrással való kapcsolatot. \textit{Pluginok}on keresztül továbbá támogatja a felhő alapú AWS Cloudwatch és OpenStack Gnocchi adatforrást is.


A Grafana legnagyobb előnye a \textit{dashboard}-jaiban rejlik. A felületen --mint egy műszerfalon-- egymás mellett rendszerezve helyezkednek el a különböző paneleken ábrázolt metrikák. Számtalan előre elkészített típusú panelből lehet válogatni, többek között elérhetőek hisztogramok, grafikonok, hőtérképek, táblázatok, riasztások, RSS- és naplóbejegyzés-olvasó felületek.

A grafana oldalán ezen kívül számos előre elkészített és szabadon felhasználható \textit{dashboard} érhető el. A leggyakrabban használt alkalmazások metrikái újra használhatóan és szerkeszthetően hozzáférhetőek. Így a fejlesztést jelentősen leegyszerűsítve, elegendő csupán az alkalmazás specifikus paneleket letölteni és testre szabni.

\subsubsection{Graphite}
A Graphite idősoros tárolására és megjelenítésére alkalmas open source moniorozó eszköz. Összesen két feladatot lát el, a Whisper könyvtárral tárolja a neki küldött adatokat, valamint megjeleníti a tárolt adatot a webes felületén.

Az adatok tárolása nem olyan kifinomult mint a Prometheuson; passzívan képes csak fogadni az adatokat és nem rendelkezik a PromQL-hez hasonló lekérdező nyelvvel sem.

A beépített felülete --körülbelül a Prometheus-éhoz hasonlóan-- messze nem olyan részletes mint a Grafanáé. Egyszerű grafikonok és táblázatok ugyanúgy elkészíthetőek vele, de ezen kívül támogatja még \textit{dashboard}ok létrehozását.


\subsubsection{Megvalósítás}
A fenti ismeretek fényében egy hibrid megoldást választottam. A Grafana könnyen integrálható a Prometheussal, így egyszerre tudom kihasználni a Grafana kifinomult megjelenítését és szerkeszthető \textit{dashboard}jait, valamint a Prometheus PromSQL-jét, kiforrott adatgyűjtési és tárolási módszereit.

\bigskip
Így tehát a springes alkamazásaim egy-egy HTTP endpointon keresztül érhetőek el a prometheus számára (\textit{\mbox{/actuator/proemtheus}}) és induláskor beregisztrálják magukat az eureka\footnote{Az Eureka a Netflix által fejlesztett \textit{discovery server}. Feladata az összes kliens port és ip adatának nyilkvántartása.} szerverbe.

A prometheus az eurekán keresztül találja meg az instanceokat, és 15 másodpercenként összegyűjti a metrikákat. Az alkalmazások információt küldenek a Kafka konnektoraikról, REST interfészeikről és az adatbázis kapcsolataikról\footnote{HikariCP-t használok JDBC kapcsolathoz}.

A Prometheus által összegyűjtött adatokat grafanában létrehozott --Spring Boot és JVM metrikákat tartalmazó-- \textit{dashboard}okon ábrázolom.


\section{E-mail kliens}
Az e-mail kliens szerepe az üzenetek küldése és fogadása egy meghatározotst e-mail címről. Feladata a külső protokollok leválasztása az alkalmazástól. Irányítja és karbantartja az IMAP és SMTP szerverrel való kapcsolatot.

\Aref{fig:email-client_sequence_diagram}. ábrán látható a két irányú kommunikáció megvalósulása:
\begin{itemize}
	\item az IMAP-on keresztül fogadott e-mailt az \textit{email.in.v1.pub} kafka topicba írja,
	\item a saját --e-mail cím specifikus-- topic-jából kiolvassa az üzenetet és továbbítja  az SMTP szerver felé.
\end{itemize}


\begin{figure}[hbt] 
	\centering
	\includegraphics[width=0.85\textwidth]{email-client_sequence_diagram_drawio.pdf}
	\caption{E-mail kliens szekvencia diagramja}
	\label{fig:email-client_sequence_diagram}
	\floatfoot{Forrás: saját ábra}
\end{figure}




\subsection{E-mail szabvány}
Az elküldött üzenetek megfelelnek az \textit{rfc5322} szabványnak, különös tekintettel a 3.6.4. pontban~\cite{rfc5322_Identification_Fields} meghatározott mezőkre:

\begin{description}
	\item[Message-ID] egy globálisan egyedi azonosító ami egyértelműen azonosítja az üzenetet,
	
	\item[In-Reply-To] válasz esetén értéke eredeti üzenet \textit{Message-ID}-ja,
	
	\item[References] azonosítja az üzenet szálat, értéke az eredeti üzenetek \textit{Message-ID}-jai vesszővel elválasztva.
\end{description}


\section{Helpdesk backend}\label{sec:backend}
A backend felelős az e-mail szálakkal kapcsolatos üzleti feladatok ellátásáért. \Aref{fig:backend_sequence_diagram}. ábrán láthatóak a helpdesk backend funkciói:
\begin{itemize}
	\item fogadja az \textit{email.in.v1.pub} kafka topic-ból érkező e-maileket, 
	\item kiszolgálja a frontend Nginx-en keresztül érkező kéréseit,
	\item a megfelelő kafka topic-ba írja az elküldendő üzeneteket,
	\item tárolja az e-mail szálakkal kapcsolatos adatokat.
\end{itemize}


\begin{figure}[hbt] 
	\centering
	\includegraphics[width=0.85\textwidth]{backend_sequence_diagram_drawio.pdf}
	\caption{Helpdesk backend szekvencia diagramja}
	\label{fig:backend_sequence_diagram}
	\floatfoot{Forrás: saját ábra}
\end{figure}


\subsection{Spring Boot}
A forráskód Spring Boot (\ref{sec:spring_boot} pont) keretrendszerrel készült. Az elérhető modulok közül a data-jpa-t az adatbázis \textit{repository}-jaihoz, a security-t a keycloak integrációhoz, a webet a \textit{rest controller}ekhez, a prometheus-t és az actuatort a metrikák elkészítéséhez használtam.	


\subsection{Adatbázis}\label{sec:adatbazis}
Az alábbi hármom relációs adatbázist vettem számításba:
\begin{itemize}
	\item Oracle DBMS,
	\item MySQL,
	\item és PostgreSQL.
\end{itemize}

Az Oracle adatbázist a drága licence miatt nem tartom jó választásnak, helyette inkább egy open source megoldást választanék.

Az alkalmazás működése szempontjából lényeges funkciók a MySQL és a PostgreSQL adatbázisban is elérhetőek.

A backend alkalmazásban az adatokat JPA-n keresztül kezelem, így --a megfelelő adatbázis kiválasztásában-- a legfontosabb szempontnak a két adatbázis Hibernaten keresztül elért teljesítményét tartom.

\subsubsection{Teljesítményvizsgálat}
Az ObjectDB által készített teljesítményvizsgálat\cite{JPA_benchmark} a saját --memóriában futtatott-- adatbázisuk teljesítményéhez hasonlítja többi alkalmazás teljesítményét (\ref{eq:normalizalt} egyenlet). Így a normalizált mérőszámok egymással összevethetőek.

\begin{equation}
\textrm{vizsgált rendszer mérőszáma} = 100 \cdot
\frac{\textrm{vizsgált rendszer teljesítménye}}{\textrm{ObjectDB teljesítménye}}
\frac{[\textrm{művelet}/s]}{[\textrm{művelet}/s]}
\label{eq:normalizalt}
\end{equation}

\Aref{tabl:teljesitmenyvizsgalat} táblázatban --a dokumentált eredményekből\cite{JPA_benchmark}-- összegyűjtöttem a vizsgálat szempontjából mérvadó adatokat. Mindegyik mérés külön példányon, egyesével, egyenként $100~000$ véletlenszerű entitás létrehozásával készült. \Aref{eq:normalizalt} egyenletből következik, hogy egy mérőszám minél magasabb értékű, a rendszer annál jobb teljesítményűnek számít.

\begin{table}[hbt]
	
	\begin{tabular}{lc|c}
		Tesztesetek & MySQL adatbázis & PostgreSQL adatbázis \\\hline 

		Új adat létrehozás & 2,8 & 7,7\\ \hline
		Keresés elsődleges kulcs alapján  & 5,2 & 7,0\\ \hline
		Keresés szóeleji egyezés alapján & 2,9 & 20,7\\ \hline
		Meglévő adat módosítása & 1,2 & 5,4\\ \hline
		Meglévő törlése & 1,2 & 6,6 \\ \hline
		Tesztesetek átlaga & 2,7 & 9,1
	\end{tabular} 
	
	\caption{JPA teljesítményvizsgálata Hibernate implemetációval és  MySQL illetve PostgreSQL adatbázissal }
	\label{tabl:teljesitmenyvizsgalat}
\end{table}



\Aref{tabl:teljesitmenyvizsgalat} táblázatban látszódik, hogy a PostgreSQL adatbázis a Hibernate implmentációval átlagosan háromszor olyan jól teljesít, mint a MySQL adatbázis. Ám ha figyelembe vesszük, hogy a két leggyakrabban előforduló funkció az elsődleges kulcs valamint szóeleji egyezés alapján keresés, akkor egyértelmű hogy a PostgreSQL adatbázist érdemes választani.


\bigskip
\subsubsection{Megvalósítás részletei}
A Spring HikariCP-n keresztül kezeli PostgreSQL adatbázishoz kapcsolódást.
Az adatok kezelését Hibernate\footnote{A Hibernate egy JPA implementáció, ami objektum relációs leképzést valósít meg}-en keresztül, az adatbázis verziókövetését Liquibase-en (\ref{sec:liquibase} pont) keresztül valósítom meg. 

Az e-mail szálak audit információinak és verzióinak követésére a Hibernate saját -- Envers (\ref{sec:hubernate_envers} pont) eszközét használom. Az Envers a neki létrehozott táblában automatikusan követi az annotációval megjelölt entitások állapotát.

\subsection{Pesszimista konkurenciakezelés}
Pesszimista konkurenciakezelésre jó példával szolgál a Liquibase (\ref{sec:liquibase} pont) működése. 

Minden indítás során a Liquibase --az adatbázis módosításának befejezéséig-- zárolja a \textit{databasechangeloglock} táblát. Így --a várakozás miatt-- egyszerre mindig maximum egy Liquibase példány tud elindulni, és módosításokat végrehajtani.


\subsection{Optimista konkurenciakezelés}
A \ref{sec:konkurencia_kezekese} pontban ismertetett optimista konkurenciakezelést az e-mail szálak módosítása során valósítja meg a backend.

A frontend kérésére egy verziószámmal ellátott e-mail szálat küld a backend. Ezt a HTTP-protokollnak megfelelő \textit{eTag}-et a frontend megőrzi, majd a módosítások elvégzését követően --mint \textit{if-match} paraméter-- visszaküldi a módosítási kérésével együtt.

A backend összehasonlítja a módosítani kívánt erőforrás verziószámát a kérésben érkezett \textit{if-match} verziószámmal. Ha a két szám egyezik, akkor végrehajtja a változásokat, és az erőforrás új állapota új verziószámot kap.

Ha a két verzió nem egyezik --ami csak úgy történhet meg, ha valaki más időközben módosította a kérdéses adatot-- akkor a tranzakció nem hajtódik végre, és a kliens egy HTTP \textit{Conflict} hibaüzenettel értesül a történtekről. A felhasználó ilyenkor az oldal frissítése után, megvizsgálja az aktuális állapotot, és --amennyiben a módosításaira még mindig szükség van-- újból kezdi a folyamatot.

\subsection{Egyéb eszközök}\label{sec:backend_egyeb_eszkozok}
A \textit{DTO}-k és az \textit{entity}k közötti leképezést a Mapstruct (\ref{sec:retegek_szeparalasa}) segítségével végzem. A REST \textit{endpoint}ok dokumentációját Swagger segítségével generálom. A Swagger a felannotált osztályokból és metódusokból szabványos OpenApi dokumnetációt készít. A dokumentációt \aref{appendix:openapi} függelékben csatoltam a dolgozatomhoz.

\bigskip


\section{Helpdesk frontend}
A frontend az e-mailek és e-mail szálakkal összefüggő üzleti feladatok megjelenítéséért felelős. A felhasználók jogosultság ellenőrzését végzi el, a bejelentkeztetésüket átirányítja a Keycloak szervernek. 


\subsection{Kommunikáció a backenddel}
A backenddel való kommunikáció HTTP protokollon keresztül zajlik, a szükséges \textit{service}-eket az OpenApi dokumnetációból (\ref{sec:backend_egyeb_eszkozok}) a \textit{swagger angular generator} hozza létre.

Az aszinkron HTTP hívásokat az NgRx könyvtár alakítja adatfolyamokká. 
Az így, \textit{Observable}-ként kezelt események már támogatják a stream műveleteket, megkönnyítik a filterezhetőséget és az egységes hibakezelést. 

Az NgRx használatával továbbá, elkerülhetőek az aszinkron hívások mellékhatásai, és egy globális, alkalmazás szintű belső állapot hozható létre.

\subsection{Komponensek}
Az egységes megjelenés és az ismerős kinézet miatt, a komponenseim alapjának az Angular Material UI könyvtárat választottam. A könyvtár	népszerű az Angular fejlesztők körében, mert a leggyakrabban előforduló felhasználói igényekre elérhető benne kész, könnyen használható megoldás.

A válasz e-mail lérehozására az open source Quill szövegszerkesztőt használtam.
Egyszerűen beilleszthető az Angular környezetbe, és a felhasználó számára intuitív kezelőfelülettel rendelkezik.


\subsection{Futtatási környezet}
A kész program egy egyszerű HTML, CSS és JavaScript állománnyá fordul. A körülbelül $1,5$~MB-nyi forráskódot elegendő a böngészőbe egyszer letölteni, onnantól a program a kliens oldalon fut (lásd \ref{fig:frontend_sequence_diagram} ábra). A backend felé induló REST kéréseket a loadbalancer (\ref{sec:nginx}) osztja szét a rendelkezésre álló példányok között.

A frontend működését, és függőségeit \aref{fig:frontend_sequence_diagram}. ábra tartalmazza.

\begin{figure}[hbp] 
	\centering
	\includegraphics[width=0.85\textwidth]{frontend_sequence_diagram_drawio.pdf}
	\caption{Helpdesk frontend szekvencia diagramja}
	\label{fig:frontend_sequence_diagram}
	\floatfoot{Forrás: saját ábra}
\end{figure}


\section{Keycloak}\label{sec:keycloak}
A Keycloak egy open source jogosultság- és hozzáférés-kezelő. Támogatja az LDAP-ot, SSO-t és a kétlépcsős azonosítást~\cite{Keycloak_website}. 

A helpdesk alkalmazásban feladata a felhasználók azonosítása, és adataiknak nyilvántartása. Különálló mikroszervizként, saját adatbázissal rendelkezik.

Adminisztrátor felülete segítségével nyomon követhető a különböző autentikációhoz köthető események, szerkeszthetőek az aktuálisan érvényes szerepkörök, és --hibakezelési céllal-- megszemélyesíthetőek a felhasználók.


\subsection{Jogosultságkezelés}
A jogosultságokat két eltérő területre osztottam fel. A \textit{master realm} a regisztrációért és a jogkörök kiosztásáért, míg a \textit{helpdesk realm} az alakalmazás funkcionális (\ref{sec:tobb_felhasznalo}) feladatiért felelős.

A \textit{helpdesk realm}on belül további két jogkört külöböztetek meg. Az \textit{admin\textunderscore user} szerepbe tartozó felhasználók képesek más e-mail szálait is kezelni, míg a csupán \textit{regular\textunderscore user} jogkörbe tartozóak csak a saját e-mail szálaikhoz férhetnek hozzá.


\subsection{JSON Web Token}\label{sec:JWT}
A jogosultságkezelés technikai alapját az \textit{rfc7519}-es szabványban \cite{rfc7519_JSON_Web_Token} leírt JSON Web Token (JWT) adja. 

A keycloak szervere által digitálisan aláírt token tartalmazza a felhasználó jogosultságait. A frontend minden HTTP lekérdezéshez csatolja a keycloaktól kapott azonosítót. A backend hitelesíti a tokent a keycloak publikus kulcsával (lásd \ref{fig:frontend_sequence_diagram} ábra), és a megfelelő jogosultság megléte esetén engedélyezi a hozzáférést az erőforráshoz.


\section{Kafka}\label{sec:implementacio_kafka}
Hogy teljesen elválasszam egymástól az e-mail klienst és a helpdesk backendet, a bejövő és kimenő e-mailek Kafka \textit{topic}-okon (\ref{sec:apache_kafka} pont) mennek keresztül. A szeparációval függetlenné teszem egymástól a két rendszer működését, ami lehetővé teszi az eltérő igénybevételnek (\ref{sec:granularitas} pont) megfelelő skálázhatóságot.

Ugyanígy, a funkciók szeparálása (\ref{sec:backend_keycloak_separation}) miatt a felhasználók adatai egy külön kafka topicban érhetőek el. Bármelyik mikroszerviznek szüksége lenne valamilyen felhasználóval kapcsolatos információra, azokat a topic vévigolvasásával megkaphatja.



\section{Helpdesk backend és a Keycloak elkülönítése}\label{sec:backend_keycloak_separation}
A felhasználók adataiért a Keycloak (\ref{sec:keycloak}), az e-mail szálakért pedig a backend (\ref{sec:backend}) felelős. Az üzleti igény megköveteli hogy a felhasználók e-mail sorokhoz, és az e-mail szálak felhasználókhoz legyenek rendelve. A helpdesk backendnek éppen ezért tárolnia kell a fennálló kapcsolatokat.

A felhasználók a Keycloak felületén keresztül tudnak regisztrálni, és a személyes adataikat kezelni. A Keycloak által generált JSON Web Token (\ref{sec:JWT}) tartalmazza a felhasználók egyedi azonosítóját, a backendnek ezen az azonosítón keresztül kell a felhasználókat nyilvántartania és kiszolgálnia.

A felhasználók regisztrációja, és adatainak változása --\aref{sec:alkalmazasok_szeparalasa} pontban megismert CQRS útnak megfelelően,-- a \textit{user.v1.pub} kafka (\ref{sec:implementacio_kafka}) topicban követhetőek nyomon.

A Keycloak Kafka integrációjának céljából hoztam létre a \textit{keycloak-plugin} (\ref{fig:deployment_diagram} ábra) maven modult. A Keycloak esemény figyelőként működő plugin, a megfigyelt eseményekről kafka üzenetet küld a kijelölt topicba. A helpdesk backend --a topic üzeneteit olvasva-- tartja karban a \textit{users} táblát (\ref{fig:basic_database_uml}, \ref{fig:extended_database_uml} ábra). Így a helpdesk backend a felhasználókról mindig aktuális információval rendelkezik.


